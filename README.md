# Scraper de OCC - Vercel Deployment

Este es un scraper de vacantes de OCC.com.mx que funciona completamente en Vercel (frontend + backend).

## 游 Despliegue en Vercel

### 1. Preparaci칩n

1. **Aseg칰rate de tener todos los archivos**:
   - `server.js` - Servidor principal (backend + frontend)
   - `scrape.js` - L칩gica del scraper
   - `package.json` - Dependencias
   - `vercel.json` - Configuraci칩n de Vercel
   - `web-interface/` - Archivos del frontend

### 2. Despliegue

#### Opci칩n A: Usando Vercel CLI
```bash
# Login a Vercel
vercel login

# Desplegar
vercel

# Para producci칩n
vercel --prod
```

#### Opci칩n B: Usando GitHub
1. Sube tu c칩digo a GitHub
2. Ve a [vercel.com](https://vercel.com)
3. Conecta tu repositorio de GitHub
4. Vercel detectar치 autom치ticamente la configuraci칩n

### 3. URLs

Una vez desplegado, tendr치s acceso a:
- **Frontend**: `https://tu-app.vercel.app/` o `https://tu-app.vercel.app/index.html`
- **Vacantes**: `https://tu-app.vercel.app/vacantes.html`
- **API**: `https://tu-app.vercel.app/search` (POST)

### 4. Endpoints

- `GET /` - Informaci칩n del API
- `GET /status` - Estado del servidor
- `POST /search` - Buscar vacantes
- `GET /index.html` - Interfaz principal
- `GET /vacantes.html` - Vista de vacantes
- `GET /resultados.json` - Descargar JSON
- `GET /resultados.csv` - Descargar CSV
- `GET /resultados.xlsx` - Descargar Excel
- `GET /resultados.pdf` - Descargar PDF

### 5. Uso del API

```javascript
// Ejemplo de uso
const response = await fetch('https://tu-app.vercel.app/search', {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json'
  },
  body: JSON.stringify({
    searchTerm: 'desarrollador'
  })
});

const data = await response.json();
console.log(data);
```

## 游댢 Configuraci칩n

### vercel.json
```json
{
  "version": 2,
  "builds": [
    {
      "src": "server.js",
      "use": "@vercel/node"
    }
  ],
  "routes": [
    {
      "src": "/api/(.*)",
      "dest": "/server.js"
    },
    {
      "src": "/search",
      "dest": "/server.js"
    },
    {
      "src": "/status",
      "dest": "/server.js"
    },
    {
      "src": "/resultados.json",
      "dest": "/server.js"
    },
    {
      "src": "/resultados.csv",
      "dest": "/server.js"
    },
    {
      "src": "/resultados.xlsx",
      "dest": "/server.js"
    },
    {
      "src": "/resultados.pdf",
      "dest": "/server.js"
    },
    {
      "src": "/index.html",
      "dest": "/server.js"
    },
    {
      "src": "/vacantes.html",
      "dest": "/server.js"
    },
    {
      "src": "/(.*)",
      "dest": "/server.js"
    }
  ],
  "functions": {
    "server.js": {
      "maxDuration": 300
    }
  }
}
```

## 游닇 Notas

- **Todo en Vercel**: Frontend y backend est치n en la misma URL
- **Mejor rendimiento**: Vercel tiene mejor soporte para Puppeteer
- **Tiempo l칤mite**: 300 segundos m치ximo por request
- **Archivos temporales**: Los archivos generados se guardan temporalmente
- **Escalabilidad**: Vercel maneja autom치ticamente la escalabilidad

## 游냍 Soluci칩n de Problemas

### Error de Puppeteer
Si ves errores de Puppeteer:
1. Verifica que `puppeteer` est칠 en las dependencias
2. Revisa los logs en Vercel Dashboard
3. Aseg칰rate de que la configuraci칩n en `scrape.js` sea correcta

### Timeout
Si el scraping toma m치s de 300 segundos:
1. Reduce el n칰mero de p치ginas a scrapear
2. Optimiza el c칩digo para ser m치s r치pido
3. Considera usar un servicio de background jobs

### Archivos no encontrados
Si los archivos generados no se encuentran:
1. Verifica que el scraping se complet칩 correctamente
2. Revisa los logs en Vercel Dashboard
3. Aseg칰rate de que las rutas est칠n configuradas correctamente

## 游꿢 Ventajas de Vercel

- **Despliegue autom치tico**: Cada push a GitHub se despliega autom치ticamente
- **CDN global**: Contenido servido desde m칰ltiples ubicaciones
- **SSL autom치tico**: Certificados HTTPS incluidos
- **Monitoreo**: Logs y m칠tricas incluidos
- **Escalabilidad**: Manejo autom치tico de tr치fico
